{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6yW1j0RhT_F"
      },
      "source": [
        "**Prepare Data Set for training of model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isXaD6kjyKVz",
        "outputId": "c67f90b7-b5c8-4bdf-a787-1cc1bc43ae6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5B_8LjwUwTb"
      },
      "outputs": [],
      "source": [
        "!pip install patchify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JhfzEhNUxht"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "from PIL import Image \n",
        "import numpy as np \n",
        "from patchify import patchify\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOjW93A1eWs-"
      },
      "outputs": [],
      "source": [
        "minmaxscaler = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3ersFuGeXx-"
      },
      "outputs": [],
      "source": [
        "dataset_root_folder='/content/drive/MyDrive/Colab Notebooks/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtxiK9FCebKc"
      },
      "outputs": [],
      "source": [
        "dataset_name=\"data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WT_NrYrZed-b"
      },
      "outputs": [],
      "source": [
        "for path, subdirs, files in os.walk(os.path.join(dataset_root_folder, dataset_name)):\n",
        "  dir_name = path.split(os.path.sep)[-1]\n",
        "  if dir_name == 'masks': # 'images\n",
        "    images = os.listdir(path)\n",
        "    for i, image_name in enumerate(images):\n",
        "      if (image_name.endswith('.png')): # '.jpg\n",
        "        a = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iayuH2DEek_l"
      },
      "outputs": [],
      "source": [
        "image_patch_size = 160"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmjwZ96BffF2"
      },
      "outputs": [],
      "source": [
        "image_dataset = []\n",
        "mask_dataset = []\n",
        "\n",
        "for image_type in ['images' , 'masks']:\n",
        "  if image_type == 'images':\n",
        "    image_extension = 'jpg'\n",
        "  elif image_type == 'masks':\n",
        "     image_extension = 'png'\n",
        "  for image_id in range(0,20):\n",
        "      image = cv2.imread(f'{dataset_root_folder}/{dataset_name}/{image_type}/0{image_id}.{image_extension}',1)\n",
        "      if image is not None:\n",
        "        if image_type == 'masks':\n",
        "          image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        size_x = (image.shape[1]//image_patch_size)*image_patch_size\n",
        "        size_y = (image.shape[0]//image_patch_size)*image_patch_size\n",
        "        image = Image.fromarray(image)\n",
        "        image = image.crop((0,0, size_x, size_y))\n",
        "        image = np.array(image)\n",
        "        patched_images = patchify(image, (image_patch_size, image_patch_size, 3), step=image_patch_size)\n",
        "        for i in range(patched_images.shape[0]):\n",
        "          for j in range(patched_images.shape[1]):\n",
        "            if image_type == 'images':\n",
        "              individual_patched_image = patched_images[i,j,:,:]\n",
        "              individual_patched_image = minmaxscaler.fit_transform(individual_patched_image.reshape(-1, individual_patched_image.shape[-1])).reshape(individual_patched_image.shape)\n",
        "              individual_patched_image = individual_patched_image[0]\n",
        "              image_dataset.append(individual_patched_image)\n",
        "            elif image_type == 'masks':\n",
        "              individual_patched_mask = patched_images[i,j,:,:]\n",
        "              individual_patched_mask = individual_patched_mask[0]\n",
        "              mask_dataset.append(individual_patched_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kseKhwVre9rU"
      },
      "outputs": [],
      "source": [
        "print(len(image_dataset))\n",
        "print(len(mask_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0JpYbY7fBYV"
      },
      "outputs": [],
      "source": [
        "image_dataset = np.array(image_dataset)\n",
        "mask_dataset = np.array(mask_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ewu_CdDfEKU"
      },
      "outputs": [],
      "source": [
        "class_vegetation = '#000000'\n",
        "class_vegetation = class_vegetation.lstrip('#')\n",
        "class_vegetation = np.array(tuple(int(class_vegetation[i:i+2], 16) for i in (0,2,4)))\n",
        "print(class_vegetation)\n",
        "\n",
        "\n",
        "class_unlabeled = '#ffffff'\n",
        "class_unlabeled = class_unlabeled.lstrip('#')\n",
        "class_unlabeled = np.array(tuple(int(class_unlabeled[i:i+2], 16) for i in (0,2,4)))\n",
        "print(class_unlabeled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "im5Lbdc6fIBx"
      },
      "outputs": [],
      "source": [
        "label = individual_patched_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWoGimDffKyq"
      },
      "outputs": [],
      "source": [
        "def rgb_to_label(label):\n",
        "  label_segment = np.zeros(label.shape, dtype=np.uint8)\n",
        "  label_segment[np.all(label == class_vegetation, axis=-1)] = 0\n",
        "  label_segment[np.all(label == class_unlabeled, axis=-1)] = 1\n",
        "  #print(label_segment)\n",
        "  label_segment = label_segment[:,:,0]\n",
        "  #print(label_segment)\n",
        "  return label_segment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfmUfJL-fOze"
      },
      "outputs": [],
      "source": [
        "labels = []\n",
        "for i in range(mask_dataset.shape[0]):\n",
        "  label = rgb_to_label(mask_dataset[i])\n",
        "  labels.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roMClCsIfR0F"
      },
      "outputs": [],
      "source": [
        "labels = np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjUsUCS6fXMJ"
      },
      "outputs": [],
      "source": [
        "labels = np.expand_dims(labels, axis=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6HRLen3fYKu"
      },
      "outputs": [],
      "source": [
        "total_classes = len(np.unique(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPSWo1jHfclb"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mUfDZHWfhwB"
      },
      "outputs": [],
      "source": [
        "labels_categorical_dataset = to_categorical(labels, num_classes=total_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLnCCVnzfl9I"
      },
      "outputs": [],
      "source": [
        "master_trianing_dataset = image_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fz_8ND1-fpOq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAF0zUgSeOMB"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(master_trianing_dataset, labels_categorical_dataset, test_size=0.15, random_state=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUwAh8Fvf3dP"
      },
      "outputs": [],
      "source": [
        "image_height = X_train.shape[1]\n",
        "image_width = X_train.shape[2]\n",
        "image_channels = X_train.shape[3]\n",
        "total_classes = y_train.shape[3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSBLnyYfwUha"
      },
      "source": [
        "**Creation of Deep Learning U-Net Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvX3j2-7wSTr"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q segmentation-models\n",
        "!pip install -q tensorflow\n",
        "!pip install -q keras\n",
        "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
        "\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nG2H9NHZxj0L"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose\n",
        "from keras.layers import concatenate, BatchNormalization, Dropout, Lambda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwrjeXSlxm7a"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0OqiOq-xpZe"
      },
      "outputs": [],
      "source": [
        "def jaccard_coef(y_true, y_pred):\n",
        "  y_true_flatten = K.flatten(y_true)\n",
        "  y_pred_flatten = K.flatten(y_pred)\n",
        "  intersection = K.sum(y_true_flatten * y_pred_flatten)\n",
        "  final_coef_value = (intersection + 1.0) / (K.sum(y_true_flatten) + K.sum(y_pred_flatten) - intersection + 1.0)\n",
        "  return final_coef_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kSENPOl3Y_m"
      },
      "outputs": [],
      "source": [
        "def multi_unet_model(n_classes=5, image_height=256, image_width=256, image_channels=1):\n",
        "\n",
        "  inputs = Input((image_height, image_width, image_channels))\n",
        "\n",
        "  source_input = inputs\n",
        "\n",
        "  c1 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(source_input)\n",
        "  c1 = Dropout(0.2)(c1)\n",
        "  c1 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c1)\n",
        "  p1 = MaxPooling2D((2,2))(c1)\n",
        "\n",
        "  c2 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p1)\n",
        "  c2 = Dropout(0.2)(c2)\n",
        "  c2 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c2)\n",
        "  p2 = MaxPooling2D((2,2))(c2)\n",
        "\n",
        "  c3 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p2)\n",
        "  c3 = Dropout(0.2)(c3)\n",
        "  c3 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c3)\n",
        "  p3 = MaxPooling2D((2,2))(c3)\n",
        "\n",
        "  c4 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p3)\n",
        "  c4 = Dropout(0.2)(c4)\n",
        "  c4 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c4)\n",
        "  p4 = MaxPooling2D((2,2))(c4)\n",
        "\n",
        "  c5 = Conv2D(256, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p4)\n",
        "  c5 = Dropout(0.2)(c5)\n",
        "  c5 = Conv2D(256, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c5)\n",
        "\n",
        "  u6 = Conv2DTranspose(128, (2,2), strides=(2,2), padding=\"same\")(c5)\n",
        "  u6 = concatenate([u6, c4])\n",
        "  c6 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u6)\n",
        "  c6 = Dropout(0.2)(c6)\n",
        "  c6 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c6)\n",
        "\n",
        "  u7 = Conv2DTranspose(64, (2,2), strides=(2,2), padding=\"same\")(c6)\n",
        "  u7 = concatenate([u7, c3])\n",
        "  c7 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u7)\n",
        "  c7 = Dropout(0.2)(c7)\n",
        "  c7 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c7)\n",
        "\n",
        "  u8 = Conv2DTranspose(32, (2,2), strides=(2,2), padding=\"same\")(c7)\n",
        "  u8 = concatenate([u8, c2])\n",
        "  c8 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u8)\n",
        "  c8 = Dropout(0.2)(c8)\n",
        "  c8 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c8)\n",
        "\n",
        "  u9 = Conv2DTranspose(16, (2,2), strides=(2,2), padding=\"same\")(c8)\n",
        "  u9 = concatenate([u9, c1], axis=3)\n",
        "  c9 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u9)\n",
        "  c9 = Dropout(0.2)(c9)\n",
        "  c9 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c9)\n",
        "\n",
        "  outputs = Conv2D(n_classes, (1,1), activation=\"softmax\")(c9)\n",
        "\n",
        "  model = Model(inputs=[inputs], outputs=[outputs])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2ipADIFxyus"
      },
      "outputs": [],
      "source": [
        "metrics = [\"accuracy\", jaccard_coef]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2FjksJGx2OC"
      },
      "outputs": [],
      "source": [
        "def get_deep_learning_model():\n",
        "  return multi_unet_model(n_classes=total_classes, \n",
        "                          image_height=image_height, \n",
        "                          image_width=image_width, \n",
        "                          image_channels=image_channels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7NIq3Ydx5ES"
      },
      "outputs": [],
      "source": [
        "model = get_deep_learning_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGhM0Jz_yM7U"
      },
      "source": [
        "--Generating Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFRiHhbMyRf2"
      },
      "outputs": [],
      "source": [
        "weights = [0.5, 0.5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_HR53sA7chU"
      },
      "outputs": [],
      "source": [
        "import segmentation_models as sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UI02q5-j7fob"
      },
      "outputs": [],
      "source": [
        "dice_loss = sm.losses.DiceLoss(class_weights = weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eu3FD8-t7h9L"
      },
      "outputs": [],
      "source": [
        "focal_loss = sm.losses.CategoricalFocalLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fCByhf97kaw"
      },
      "outputs": [],
      "source": [
        "total_loss = dice_loss + (1 * focal_loss)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
